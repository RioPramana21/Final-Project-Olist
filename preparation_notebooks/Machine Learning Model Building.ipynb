{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e7106ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling & Manipulation\n",
    "import pandas as pd                                         # for dataframes, CSV/Excel reading, tabular data manipulation\n",
    "import numpy as np                                          # for numerical operations and array handling\n",
    "import datetime                                             # for date and time manipulation\n",
    "from datetime import datetime, timedelta                    # for date arithmetic (e.g., adding days)\n",
    "from workalendar.america import Brazil                      # for Brazilian holidays (e.g., to check if a date is a holiday)\n",
    "\n",
    "# Data Visualisation (Static)\n",
    "import matplotlib.pyplot as plt                             # for creating static plots\n",
    "from matplotlib.ticker import FuncFormatter                 # for customising tick labels (e.g., currency, %)\n",
    "import seaborn as sns                                       # for statistical visualisation (heatmaps, distplots, etc.)\n",
    "\n",
    "# Data Visualisation (Interactive)\n",
    "import plotly.express as px                                 # for quick and interactive visualisation\n",
    "import plotly.graph_objects as go                           # for custom interactive plots\n",
    "from plotly.subplots import make_subplots                   # for interactive subplots\n",
    "\n",
    "# Data Quality & Missing Value Visualisation\n",
    "import missingno as msno                                    # for visualising missing data patterns\n",
    "\n",
    "# Statistical Testing & Inference\n",
    "from statsmodels.stats.proportion import proportions_ztest  # for comparing proportions (e.g., late vs. on-time)\n",
    "from scipy.stats import (\n",
    "    normaltest,                                             # for checking normality\n",
    "    chi2_contingency,                                       # for categorical association\n",
    "    mannwhitneyu,                                           # for non-parametric testing\n",
    "    ttest_ind,                                              # for independent sample t-test\n",
    "    f_oneway,                                               # for one-way ANOVA\n",
    "    kruskal,                                                # for Kruskal-Wallis test\n",
    "    kstest,                                                 # for Kolmogorov-Smirnov test\n",
    "    spearmanr,                                              # for Spearman correlation\n",
    "    pointbiserialr                                          # for point-biserial correlation (binary vs. continuous)\n",
    ")\n",
    "import statsmodels.api as sm                                # for advanced statistical modelling and diagnostics\n",
    "import statsmodels.formula.api as smf                       # for formula-based statistical models\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd   # for post-hoc tests after ANOVA\n",
    "\n",
    "# System & Settings\n",
    "import os                                                   # for file handling and directory operations\n",
    "import warnings                                             # to suppress or manage warning messages\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.set_option('display.max_colwidth', None)                 # display full content in cells (useful for text data)\n",
    "\n",
    "# Machine Learning & Model Evaluation\n",
    "import joblib                                               # for saving and loading ML models\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import (\n",
    "    average_precision_score, precision_recall_fscore_support,\n",
    "    confusion_matrix, PrecisionRecallDisplay, make_scorer\n",
    ")\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier           # for KNN classifier (added since it's in your benchmark)\n",
    "from sklearn.tree import DecisionTreeClassifier              # for Decision Tree classifier (added since it's in your benchmark)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier                           # for XGBoost classifier\n",
    "from lightgbm import LGBMClassifier                         # for LightGBM classifier\n",
    "from catboost import CatBoostClassifier, Pool               # for CatBoost classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22631357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of date columns for each Olist dataset:\n",
    "# This dictionary maps each dataset filename to a list of columns that should be parsed as dates.\n",
    "date_cols = {\n",
    "    'olist_orders_dataset.csv': [\n",
    "        'order_purchase_timestamp',\n",
    "        'order_approved_at',\n",
    "        'order_delivered_carrier_date',\n",
    "        'order_delivered_customer_date',\n",
    "        'order_estimated_delivery_date',\n",
    "    ],\n",
    "    'olist_order_items_dataset.csv': [\n",
    "        'shipping_limit_date',\n",
    "    ],\n",
    "    'olist_order_reviews_dataset.csv': [\n",
    "        'review_creation_date',\n",
    "        'review_answer_timestamp',\n",
    "    ],\n",
    "    # The following datasets have NO date columns:\n",
    "    # 'olist_customers_dataset.csv'\n",
    "    # 'olist_geolocation_dataset.csv'\n",
    "    # 'olist_order_payments_dataset.csv'\n",
    "    # 'olist_products_dataset.csv'\n",
    "    # 'olist_sellers_dataset.csv'\n",
    "    # 'product_category_name_translation.csv'\n",
    "    'master_olist_dataset.csv': [\n",
    "        'order_purchase_timestamp',\n",
    "        'order_approved_at',\n",
    "        'order_delivered_carrier_date',\n",
    "        'order_delivered_customer_date',\n",
    "        'order_estimated_delivery_date',\n",
    "        'shipping_limit_date',\n",
    "        'review_creation_date',\n",
    "        'review_answer_timestamp',\n",
    "    ],\n",
    "}\n",
    "\n",
    "def read_olist_csv(path):\n",
    "    \"\"\"\n",
    "    Reads an Olist CSV and parses dates for the correct columns.\n",
    "    Args:\n",
    "        path (str): Path to the CSV file.\n",
    "    Returns:\n",
    "        pd.DataFrame: Loaded dataframe with date columns parsed as datetime.\n",
    "    \"\"\"\n",
    "    # Extract just the filename, e.g., 'olist_orders_dataset.csv':\n",
    "    filename = os.path.basename(path)\n",
    "    # Get the correct date columns for this file, or an empty list:\n",
    "    parse_dates = date_cols.get(filename, [])\n",
    "    # Read the CSV, parsing the specified date columns (if any):\n",
    "    return pd.read_csv(path, parse_dates=parse_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6926df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_to_approve_hrs</th>\n",
       "      <th>approve_to_estimated_days</th>\n",
       "      <th>approve_to_shipping_limit_days</th>\n",
       "      <th>purchase_hour</th>\n",
       "      <th>purchase_dow</th>\n",
       "      <th>purchase_month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_brazil_holiday</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>same_state</th>\n",
       "      <th>...</th>\n",
       "      <th>total_order_lifetime</th>\n",
       "      <th>sum_freight_value</th>\n",
       "      <th>price</th>\n",
       "      <th>total_payment_value</th>\n",
       "      <th>customer_state</th>\n",
       "      <th>seller_state</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>product_category_name_english</th>\n",
       "      <th>payment_types</th>\n",
       "      <th>is_late</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178333</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.657513</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>53</td>\n",
       "      <td>8.72</td>\n",
       "      <td>29.99</td>\n",
       "      <td>38.71</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>8.72</td>\n",
       "      <td>housewares</td>\n",
       "      <td>credit_card, voucher</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.713889</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>861.068703</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>125</td>\n",
       "      <td>22.76</td>\n",
       "      <td>118.70</td>\n",
       "      <td>141.46</td>\n",
       "      <td>BA</td>\n",
       "      <td>SP</td>\n",
       "      <td>22.76</td>\n",
       "      <td>perfumery</td>\n",
       "      <td>boleto</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.276111</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>514.560686</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1148</td>\n",
       "      <td>19.22</td>\n",
       "      <td>159.90</td>\n",
       "      <td>179.12</td>\n",
       "      <td>GO</td>\n",
       "      <td>SP</td>\n",
       "      <td>19.22</td>\n",
       "      <td>auto</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.298056</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1821.871635</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>155</td>\n",
       "      <td>27.20</td>\n",
       "      <td>45.00</td>\n",
       "      <td>72.20</td>\n",
       "      <td>RN</td>\n",
       "      <td>MG</td>\n",
       "      <td>27.20</td>\n",
       "      <td>pet_shop</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.030556</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.623876</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>171</td>\n",
       "      <td>8.72</td>\n",
       "      <td>19.90</td>\n",
       "      <td>28.62</td>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>8.72</td>\n",
       "      <td>stationery</td>\n",
       "      <td>credit_card</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   purchase_to_approve_hrs  approve_to_estimated_days  \\\n",
       "0                 0.178333                         15   \n",
       "1                30.713889                         17   \n",
       "2                 0.276111                         26   \n",
       "3                 0.298056                         26   \n",
       "4                 1.030556                         12   \n",
       "\n",
       "   approve_to_shipping_limit_days  purchase_hour  purchase_dow  \\\n",
       "0                               4             10             0   \n",
       "1                               4             20             1   \n",
       "2                               5              8             2   \n",
       "3                               5             19             5   \n",
       "4                               5             21             1   \n",
       "\n",
       "   purchase_month  is_weekend  is_brazil_holiday  distance_km  same_state  \\\n",
       "0              10           0                  0    18.657513           1   \n",
       "1               7           0                  0   861.068703           0   \n",
       "2               8           0                  0   514.560686           0   \n",
       "3              11           1                  0  1821.871635           0   \n",
       "4               2           0                  0    29.623876           1   \n",
       "\n",
       "   ...  total_order_lifetime  sum_freight_value   price  total_payment_value  \\\n",
       "0  ...                    53               8.72   29.99                38.71   \n",
       "1  ...                   125              22.76  118.70               141.46   \n",
       "2  ...                  1148              19.22  159.90               179.12   \n",
       "3  ...                   155              27.20   45.00                72.20   \n",
       "4  ...                   171               8.72   19.90                28.62   \n",
       "\n",
       "   customer_state  seller_state  freight_value  product_category_name_english  \\\n",
       "0              SP            SP           8.72                     housewares   \n",
       "1              BA            SP          22.76                      perfumery   \n",
       "2              GO            SP          19.22                           auto   \n",
       "3              RN            MG          27.20                       pet_shop   \n",
       "4              SP            SP           8.72                     stationery   \n",
       "\n",
       "          payment_types  is_late  \n",
       "0  credit_card, voucher    False  \n",
       "1                boleto    False  \n",
       "2           credit_card    False  \n",
       "3           credit_card    False  \n",
       "4           credit_card    False  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_olist_csv('../data/cleaned_data/olist_ml_ready_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d466838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109933 entries, 0 to 109932\n",
      "Data columns (total 29 columns):\n",
      " #   Column                                          Non-Null Count   Dtype  \n",
      "---  ------                                          --------------   -----  \n",
      " 0   purchase_to_approve_hrs                         109933 non-null  float64\n",
      " 1   approve_to_estimated_days                       109933 non-null  int64  \n",
      " 2   approve_to_shipping_limit_days                  109933 non-null  int64  \n",
      " 3   purchase_hour                                   109933 non-null  int64  \n",
      " 4   purchase_dow                                    109933 non-null  int64  \n",
      " 5   purchase_month                                  109933 non-null  int64  \n",
      " 6   is_weekend                                      109933 non-null  int64  \n",
      " 7   is_brazil_holiday                               109933 non-null  int64  \n",
      " 8   distance_km                                     109933 non-null  float64\n",
      " 9   same_state                                      109933 non-null  int64  \n",
      " 10  freight_ratio                                   109933 non-null  float64\n",
      " 11  customer_is_remote                              109933 non-null  int64  \n",
      " 12  seller_dispatch_hub                             109933 non-null  float64\n",
      " 13  seller_30d_late_rate_is_dispatch_late_raw       109933 non-null  float64\n",
      " 14  seller_30d_late_rate_is_dispatch_late_smoothed  109933 non-null  float64\n",
      " 15  seller_30d_order_count                          109933 non-null  float64\n",
      " 16  seller_90d_late_rate_is_dispatch_late_raw       109933 non-null  float64\n",
      " 17  seller_90d_late_rate_is_dispatch_late_smoothed  109933 non-null  float64\n",
      " 18  seller_90d_order_count                          109933 non-null  float64\n",
      " 19  total_order_lifetime                            109933 non-null  int64  \n",
      " 20  sum_freight_value                               109933 non-null  float64\n",
      " 21  price                                           109933 non-null  float64\n",
      " 22  total_payment_value                             109933 non-null  float64\n",
      " 23  customer_state                                  109933 non-null  object \n",
      " 24  seller_state                                    109933 non-null  object \n",
      " 25  freight_value                                   109933 non-null  float64\n",
      " 26  product_category_name_english                   109933 non-null  object \n",
      " 27  payment_types                                   109933 non-null  object \n",
      " 28  is_late                                         109933 non-null  bool   \n",
      "dtypes: bool(1), float64(14), int64(10), object(4)\n",
      "memory usage: 23.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5d1d23",
   "metadata": {},
   "source": [
    "Change the target variable (`is_late`) to an int for the model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb88f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_late'] = df['is_late'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3717d5",
   "metadata": {},
   "source": [
    "Numerical features descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9345dd55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>purchase_to_approve_hrs</th>\n",
       "      <th>approve_to_estimated_days</th>\n",
       "      <th>approve_to_shipping_limit_days</th>\n",
       "      <th>purchase_hour</th>\n",
       "      <th>purchase_dow</th>\n",
       "      <th>purchase_month</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>is_brazil_holiday</th>\n",
       "      <th>distance_km</th>\n",
       "      <th>same_state</th>\n",
       "      <th>freight_ratio</th>\n",
       "      <th>customer_is_remote</th>\n",
       "      <th>seller_dispatch_hub</th>\n",
       "      <th>seller_30d_late_rate_is_dispatch_late_raw</th>\n",
       "      <th>seller_30d_late_rate_is_dispatch_late_smoothed</th>\n",
       "      <th>seller_30d_order_count</th>\n",
       "      <th>seller_90d_late_rate_is_dispatch_late_raw</th>\n",
       "      <th>seller_90d_late_rate_is_dispatch_late_smoothed</th>\n",
       "      <th>seller_90d_order_count</th>\n",
       "      <th>total_order_lifetime</th>\n",
       "      <th>sum_freight_value</th>\n",
       "      <th>price</th>\n",
       "      <th>total_payment_value</th>\n",
       "      <th>freight_value</th>\n",
       "      <th>is_late</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.00000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "      <td>109933.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.533222</td>\n",
       "      <td>22.912974</td>\n",
       "      <td>5.985355</td>\n",
       "      <td>14.751258</td>\n",
       "      <td>2.746537</td>\n",
       "      <td>6.030701</td>\n",
       "      <td>0.227302</td>\n",
       "      <td>0.027699</td>\n",
       "      <td>596.771304</td>\n",
       "      <td>0.361820</td>\n",
       "      <td>0.320681</td>\n",
       "      <td>0.278088</td>\n",
       "      <td>0.627820</td>\n",
       "      <td>0.042141</td>\n",
       "      <td>0.123733</td>\n",
       "      <td>35.309880</td>\n",
       "      <td>0.044501</td>\n",
       "      <td>0.095948</td>\n",
       "      <td>90.02809</td>\n",
       "      <td>422.691303</td>\n",
       "      <td>27.248761</td>\n",
       "      <td>120.044161</td>\n",
       "      <td>179.509910</td>\n",
       "      <td>19.949499</td>\n",
       "      <td>0.079212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>21.000989</td>\n",
       "      <td>8.832961</td>\n",
       "      <td>5.467422</td>\n",
       "      <td>5.319016</td>\n",
       "      <td>1.963767</td>\n",
       "      <td>3.233580</td>\n",
       "      <td>0.419091</td>\n",
       "      <td>0.164109</td>\n",
       "      <td>587.318831</td>\n",
       "      <td>0.480529</td>\n",
       "      <td>0.342008</td>\n",
       "      <td>0.448059</td>\n",
       "      <td>0.160439</td>\n",
       "      <td>0.129461</td>\n",
       "      <td>0.124669</td>\n",
       "      <td>49.067543</td>\n",
       "      <td>0.115396</td>\n",
       "      <td>0.114392</td>\n",
       "      <td>127.36208</td>\n",
       "      <td>556.063689</td>\n",
       "      <td>33.270072</td>\n",
       "      <td>182.449223</td>\n",
       "      <td>271.586656</td>\n",
       "      <td>15.701392</td>\n",
       "      <td>0.270070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001502</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>9.590000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.216389</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>185.951083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.515419</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023158</td>\n",
       "      <td>12.00000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>14.290000</td>\n",
       "      <td>39.900000</td>\n",
       "      <td>65.550000</td>\n",
       "      <td>13.080000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.350556</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>433.348916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>35.00000</td>\n",
       "      <td>171.000000</td>\n",
       "      <td>18.160000</td>\n",
       "      <td>74.900000</td>\n",
       "      <td>114.340000</td>\n",
       "      <td>16.260000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.194722</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>793.859072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393229</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.732713</td>\n",
       "      <td>0.012987</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>105.00000</td>\n",
       "      <td>521.000000</td>\n",
       "      <td>29.170000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>194.910000</td>\n",
       "      <td>21.150000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>741.443611</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>1051.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3398.548220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.300000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966387</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>382.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>699.00000</td>\n",
       "      <td>1992.000000</td>\n",
       "      <td>1794.960000</td>\n",
       "      <td>6735.000000</td>\n",
       "      <td>13664.080000</td>\n",
       "      <td>409.680000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       purchase_to_approve_hrs  approve_to_estimated_days  \\\n",
       "count            109933.000000              109933.000000   \n",
       "mean                 10.533222                  22.912974   \n",
       "std                  21.000989                   8.832961   \n",
       "min                   0.000000                  -7.000000   \n",
       "25%                   0.216389                  17.000000   \n",
       "50%                   0.350556                  22.000000   \n",
       "75%                  15.194722                  28.000000   \n",
       "max                 741.443611                 153.000000   \n",
       "\n",
       "       approve_to_shipping_limit_days  purchase_hour   purchase_dow  \\\n",
       "count                   109933.000000  109933.000000  109933.000000   \n",
       "mean                         5.985355      14.751258       2.746537   \n",
       "std                          5.467422       5.319016       1.963767   \n",
       "min                         -7.000000       0.000000       0.000000   \n",
       "25%                          4.000000      11.000000       1.000000   \n",
       "50%                          6.000000      15.000000       3.000000   \n",
       "75%                          6.000000      19.000000       4.000000   \n",
       "max                       1051.000000      23.000000       6.000000   \n",
       "\n",
       "       purchase_month     is_weekend  is_brazil_holiday    distance_km  \\\n",
       "count   109933.000000  109933.000000      109933.000000  109933.000000   \n",
       "mean         6.030701       0.227302           0.027699     596.771304   \n",
       "std          3.233580       0.419091           0.164109     587.318831   \n",
       "min          1.000000       0.000000           0.000000       0.000000   \n",
       "25%          3.000000       0.000000           0.000000     185.951083   \n",
       "50%          6.000000       0.000000           0.000000     433.348916   \n",
       "75%          8.000000       0.000000           0.000000     793.859072   \n",
       "max         12.000000       1.000000           1.000000    3398.548220   \n",
       "\n",
       "          same_state  freight_ratio  customer_is_remote  seller_dispatch_hub  \\\n",
       "count  109933.000000  109933.000000       109933.000000        109933.000000   \n",
       "mean        0.361820       0.320681            0.278088             0.627820   \n",
       "std         0.480529       0.342008            0.448059             0.160439   \n",
       "min         0.000000       0.000000            0.000000             0.074074   \n",
       "25%         0.000000       0.134536            0.000000             0.515419   \n",
       "50%         0.000000       0.231806            0.000000             0.601190   \n",
       "75%         1.000000       0.393229            1.000000             0.732713   \n",
       "max         1.000000      22.300000            1.000000             0.966387   \n",
       "\n",
       "       seller_30d_late_rate_is_dispatch_late_raw  \\\n",
       "count                              109933.000000   \n",
       "mean                                    0.042141   \n",
       "std                                     0.129461   \n",
       "min                                     0.000000   \n",
       "25%                                     0.000000   \n",
       "50%                                     0.000000   \n",
       "75%                                     0.012987   \n",
       "max                                     1.000000   \n",
       "\n",
       "       seller_30d_late_rate_is_dispatch_late_smoothed  seller_30d_order_count  \\\n",
       "count                                   109933.000000           109933.000000   \n",
       "mean                                         0.123733               35.309880   \n",
       "std                                          0.124669               49.067543   \n",
       "min                                          0.002604                1.000000   \n",
       "25%                                          0.037037                6.000000   \n",
       "50%                                          0.083333               15.000000   \n",
       "75%                                          0.166667               42.000000   \n",
       "max                                          0.916667              382.000000   \n",
       "\n",
       "       seller_90d_late_rate_is_dispatch_late_raw  \\\n",
       "count                              109933.000000   \n",
       "mean                                    0.044501   \n",
       "std                                     0.115396   \n",
       "min                                     0.000000   \n",
       "25%                                     0.000000   \n",
       "50%                                     0.000000   \n",
       "75%                                     0.035714   \n",
       "max                                     1.000000   \n",
       "\n",
       "       seller_90d_late_rate_is_dispatch_late_smoothed  seller_90d_order_count  \\\n",
       "count                                   109933.000000            109933.00000   \n",
       "mean                                         0.095948                90.02809   \n",
       "std                                          0.114392               127.36208   \n",
       "min                                          0.001502                 1.00000   \n",
       "25%                                          0.023158                12.00000   \n",
       "50%                                          0.054054                35.00000   \n",
       "75%                                          0.125000               105.00000   \n",
       "max                                          0.923077               699.00000   \n",
       "\n",
       "       total_order_lifetime  sum_freight_value          price  \\\n",
       "count         109933.000000      109933.000000  109933.000000   \n",
       "mean             422.691303          27.248761     120.044161   \n",
       "std              556.063689          33.270072     182.449223   \n",
       "min                1.000000           0.000000       0.850000   \n",
       "25%               57.000000          14.290000      39.900000   \n",
       "50%              171.000000          18.160000      74.900000   \n",
       "75%              521.000000          29.170000     134.500000   \n",
       "max             1992.000000        1794.960000    6735.000000   \n",
       "\n",
       "       total_payment_value  freight_value        is_late  \n",
       "count        109933.000000  109933.000000  109933.000000  \n",
       "mean            179.509910      19.949499       0.079212  \n",
       "std             271.586656      15.701392       0.270070  \n",
       "min               9.590000       0.000000       0.000000  \n",
       "25%              65.550000      13.080000       0.000000  \n",
       "50%             114.340000      16.260000       0.000000  \n",
       "75%             194.910000      21.150000       0.000000  \n",
       "max           13664.080000     409.680000       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set pandas to display all columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_rows', 10)\n",
    "# pd.set_option('display.width', 1000)\n",
    "\n",
    "# Get descriptive statistics for numerical features\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f74c037",
   "metadata": {},
   "source": [
    "Categorical features descriptive statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc21f62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_state</th>\n",
       "      <th>seller_state</th>\n",
       "      <th>product_category_name_english</th>\n",
       "      <th>payment_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>109933</td>\n",
       "      <td>109933</td>\n",
       "      <td>109933</td>\n",
       "      <td>109933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>27</td>\n",
       "      <td>22</td>\n",
       "      <td>74</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SP</td>\n",
       "      <td>SP</td>\n",
       "      <td>bed_bath_table</td>\n",
       "      <td>credit_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>46345</td>\n",
       "      <td>78416</td>\n",
       "      <td>10929</td>\n",
       "      <td>81901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       customer_state seller_state product_category_name_english payment_types\n",
       "count          109933       109933                        109933        109933\n",
       "unique             27           22                            74             6\n",
       "top                SP           SP                bed_bath_table   credit_card\n",
       "freq            46345        78416                         10929         81901"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744cbcd5",
   "metadata": {},
   "source": [
    "## Constant Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f89a0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "RANDOM_STATE = 21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392441a",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a1b5c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate X and y\n",
    "X = df.drop(columns=['is_late'])\n",
    "y = df['is_late']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce8a9d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07920769563141018 0.0792286351025606\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=TEST_SIZE, \n",
    "    stratify=y, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(y_train.mean(), y_test.mean())  # Quick check: class balance is preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36063c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shapes:\n",
      "X shape: (109933, 28)\n",
      "y shape: (109933,)\n",
      "\n",
      "Train-test split shapes:\n",
      "X_train shape: (87946, 28)\n",
      "y_train shape: (87946,)\n",
      "X_test shape: (21987, 28)\n",
      "y_test shape: (21987,)\n",
      "\n",
      "Class distribution:\n",
      "y_train value counts: is_late\n",
      "0    80980\n",
      "1     6966\n",
      "Name: count, dtype: int64\n",
      "y_test value counts: is_late\n",
      "0    20245\n",
      "1     1742\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print shape of the original X and y\n",
    "print(\"Original data shapes:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# Print shape of train and test data\n",
    "print(\"\\nTrain-test split shapes:\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Print class distribution in train and test sets\n",
    "print(\"\\nClass distribution:\")\n",
    "print(f\"y_train value counts: {y_train.value_counts()}\")\n",
    "print(f\"y_test value counts: {y_test.value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbb1c7b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "405d3c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 109933 entries, 0 to 109932\n",
      "Data columns (total 28 columns):\n",
      " #   Column                                          Non-Null Count   Dtype  \n",
      "---  ------                                          --------------   -----  \n",
      " 0   purchase_to_approve_hrs                         109933 non-null  float64\n",
      " 1   approve_to_estimated_days                       109933 non-null  int64  \n",
      " 2   approve_to_shipping_limit_days                  109933 non-null  int64  \n",
      " 3   purchase_hour                                   109933 non-null  int64  \n",
      " 4   purchase_dow                                    109933 non-null  int64  \n",
      " 5   purchase_month                                  109933 non-null  int64  \n",
      " 6   is_weekend                                      109933 non-null  int64  \n",
      " 7   is_brazil_holiday                               109933 non-null  int64  \n",
      " 8   distance_km                                     109933 non-null  float64\n",
      " 9   same_state                                      109933 non-null  int64  \n",
      " 10  freight_ratio                                   109933 non-null  float64\n",
      " 11  customer_is_remote                              109933 non-null  int64  \n",
      " 12  seller_dispatch_hub                             109933 non-null  float64\n",
      " 13  seller_30d_late_rate_is_dispatch_late_raw       109933 non-null  float64\n",
      " 14  seller_30d_late_rate_is_dispatch_late_smoothed  109933 non-null  float64\n",
      " 15  seller_30d_order_count                          109933 non-null  float64\n",
      " 16  seller_90d_late_rate_is_dispatch_late_raw       109933 non-null  float64\n",
      " 17  seller_90d_late_rate_is_dispatch_late_smoothed  109933 non-null  float64\n",
      " 18  seller_90d_order_count                          109933 non-null  float64\n",
      " 19  total_order_lifetime                            109933 non-null  int64  \n",
      " 20  sum_freight_value                               109933 non-null  float64\n",
      " 21  price                                           109933 non-null  float64\n",
      " 22  total_payment_value                             109933 non-null  float64\n",
      " 23  customer_state                                  109933 non-null  object \n",
      " 24  seller_state                                    109933 non-null  object \n",
      " 25  freight_value                                   109933 non-null  float64\n",
      " 26  product_category_name_english                   109933 non-null  object \n",
      " 27  payment_types                                   109933 non-null  object \n",
      "dtypes: float64(14), int64(10), object(4)\n",
      "memory usage: 23.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d6db69",
   "metadata": {},
   "source": [
    "> Remember: decide to use raw/smoothed features, not both!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9119071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column groups\n",
    "num_cols = [\n",
    "    'purchase_to_approve_hrs', 'approve_to_estimated_days', 'approve_to_shipping_limit_days',\n",
    "    'distance_km', 'freight_ratio', 'seller_dispatch_hub', 'seller_30d_order_count', 'seller_30d_late_rate_is_dispatch_late_raw',\n",
    "    'seller_30d_late_rate_is_dispatch_late_smoothed', 'seller_90d_order_count', 'seller_90d_late_rate_is_dispatch_late_raw',\n",
    "    'seller_90d_late_rate_is_dispatch_late_smoothed', 'total_order_lifetime', 'sum_freight_value', 'price',\n",
    "    'total_payment_value', 'freight_value'\n",
    "]\n",
    "bin_cols = [\n",
    "    'is_weekend', 'is_brazil_holiday', 'same_state', 'customer_is_remote'\n",
    "]\n",
    "cat_cols = [\n",
    "    'customer_state', 'seller_state', 'product_category_name_english', 'payment_types',\n",
    "    'purchase_hour', 'purchase_dow', 'purchase_month'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "91bb3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing pipeline for sklearn models (OHE + scaler)\n",
    "preprocess_ohe = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(), num_cols),\n",
    "    (\"cat\", OneHotEncoder(drop='first', handle_unknown=\"ignore\"), cat_cols),\n",
    "    (\"bin\", \"passthrough\", bin_cols)\n",
    "])\n",
    "\n",
    "# 5. For CatBoost: no OHE (native handling)\n",
    "preprocess_passthrough = \"passthrough\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "040b9b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "models = {\n",
    "    \"Dummy\":         (DummyClassifier(strategy=\"most_frequent\"), preprocess_passthrough),\n",
    "    \"LogReg\":        (LogisticRegression(max_iter=300, class_weight=\"balanced\", solver=\"lbfgs\", random_state=RANDOM_STATE), preprocess_ohe),\n",
    "    \"DecisionTree\":  (DecisionTreeClassifier(max_depth=None, min_samples_leaf=10, class_weight=\"balanced\", random_state=RANDOM_STATE), preprocess_ohe),\n",
    "    \"RandomForest\":  (RandomForestClassifier(n_estimators=300, max_depth=None, class_weight=\"balanced\", n_jobs=-1, random_state=RANDOM_STATE), preprocess_ohe),\n",
    "    \"XGBoost\":      (XGBClassifier(\n",
    "                        n_estimators=300,\n",
    "                        learning_rate=0.1,\n",
    "                        scale_pos_weight=pos_weight,\n",
    "                        use_label_encoder=False,         \n",
    "                        eval_metric='logloss',\n",
    "                        n_jobs=-1,\n",
    "                        random_state=RANDOM_STATE\n",
    "                     ),     preprocess_ohe),\n",
    "    \"LightGBM\":      (LGBMClassifier(n_estimators=300, learning_rate=0.1, class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=-1), preprocess_ohe),\n",
    "    \"CatBoost\":      (CatBoostClassifier(iterations=300, learning_rate=0.1, depth=6, random_state=RANDOM_STATE, verbose=0, cat_features=cat_cols, allow_writing_files=False), preprocess_passthrough)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaee91d",
   "metadata": {},
   "source": [
    "## Model Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ab46c",
   "metadata": {},
   "source": [
    "| Model                                       | What it is                                                                                                                         | Key params shown                                                                                                                                                                                                                                                                                                                         | Why we set them that way                                                                                                                                                                     |\n",
    "| ------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **DummyClassifier**<br>*(“most\\_frequent”)* | A baseline that always predicts the majority class.                                                                                | `strategy=\"most_frequent\"`                                                                                                                                                                                                                                                                                                               | Establishes a “zero-skill” floor. If any real model can’t beat its PR-AUC, something’s wrong.                                                                                                |\n",
    "| **LogisticRegression**                      | A linear classifier that outputs log-odds. Works well when the relationship is close to linear and features are well-scaled/OHE’d. | `max_iter=200` → ensures convergence.<br>`class_weight=\"balanced\"` → multiplies positive rows’ loss by **8×** (≈ 1/imbalance) so the model pays attention to minority class.<br>`solver=\"lbfgs\"` → efficient for ≤ thousands of variables.<br>`random_state` → reproducibility.                                                          | Balancing is crucial: with only \\~8 % “late” rows, an unbalanced logistic reg would almost ignore them, hurting recall & PR-AUC.                                                             |\n",
    "| **KNeighborsClassifier**                    | Instance-based learner: class of a test point = majority of its *k* nearest labelled points.                                       | `n_neighbors=15` → bigger *k* smooths noisy minority labels and limits over-fitting on class-imbalanced data.<br>`weights=\"distance\"` → nearer neighbours count more (empirically better than uniform).<br>`n_jobs=-1` → parallel CPU.                                                                                                   | Gives a non-parametric baseline that relies purely on the training geometry; sensitive to scaling, hence inside OHE+scaler preproc.                                                          |\n",
    "| **DecisionTreeClassifier**                  | A single CART tree; splits data into rectangles that are as pure as possible wrt the target.                                       | `max_depth=None` → allow full growth.<br>`min_samples_leaf=10` → prunes tiny leaves (reduces over-fit, improves PR-AUC stability).<br>`class_weight=\"balanced\"` → adjusts impurity calculation for imbalance.<br>`random_state`                                                                                                          | A tree by itself is interpretable; the leaf-size and class-weight reduce its bias toward majority class.                                                                                     |\n",
    "| **RandomForestClassifier**                  | Bagging ensemble of many CART trees; each sees a bootstrap sample ⟹ variance reduction.                                            | `n_estimators=300` → enough trees for stable out-of-bag vote, but still quick.<br>`max_depth=None` (let trees grow; forest averaging controls over-fit).<br>`class_weight=\"balanced\"` (each split weighs minority more).<br>`n_jobs=-1` (multi-core).                                                                                    | Forests work well on tabular data with mixed types and little tuning. Class-weight helps recall for the rare “late” class.                                                                   |\n",
    "| **XGBClassifier** *(XGBoost)*               | Gradient-boosted trees: sequential trees correct predecessors; powerful on tabular data.                                           | `n_estimators=300`, `learning_rate=0.1` → classic “slow-learn” setting (300×0.1 ≈ 30 effective trees).<br>`scale_pos_weight=pos_weight` → **tells XGBoost to up-weight positive gradients** (see below).<br>`eval_metric='logloss'` → matches our PR-AUC focus (probability calibration).<br>`verbosity=0`, `n_jobs=-1`, `random_state`. | Scale-pos-weight handles imbalance natively; with 8 % positives, it’s ≈ 12:1.                                                                                                                |\n",
    "| **LightGBMClassifier**                      | Microsoft’s fast gradient-boosted trees; similar to XGB but faster on large OHE matrices.                                          | `n_estimators=300`, `learning_rate=0.1` (same logic).<br>`class_weight=\"balanced\"` (built-in weight factor).<br>`n_jobs=-1`, `random_state`.                                                                                                                                                                                             | Quick benchmark of a second GBDT implementation—often top performer on tabular + categorical-encoded data.                                                                                   |\n",
    "| **CatBoostClassifier**                      | Gradient boosting that handles categorical features natively (no OHE) using target-based stats.                                    | `iterations=300`, `learning_rate=0.1` (≈ same boosting depth).<br>`depth=6` (tree depth).<br>`cat_features=cat_cols` to auto-encode categories.<br>`verbose=0`, `random_state`.                                                                                                                                                          | Eliminates the need for OHE and usually excels when many categorical columns exist. Class weighting is automatic inside CatBoost; 300 iterations keeps runtime low but gives a strong model. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d776ae3b",
   "metadata": {},
   "source": [
    "**What is `pos_weight` and why do we use it?**\n",
    "\n",
    "In imbalanced classification problems like this one—where only about 8% of the orders are late—models tend to favor predicting the majority class (\"on-time\") and may ignore the minority class (\"late\").\n",
    "\n",
    "To address this, **XGBoost provides a parameter called `scale_pos_weight`**, which increases the importance of the positive class during training.\n",
    "\n",
    "We calculate it using:\n",
    "\n",
    "```python\n",
    "pos_weight = (number of negative samples) / (number of positive samples)\n",
    "```\n",
    "\n",
    "Example:\n",
    "\n",
    "```python\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "# ≈ 80980 / 6966 ≈ 11.6\n",
    "```\n",
    "\n",
    "This tells the model to treat each late order as approximately 11.6 times more important than an on-time one.\n",
    "\n",
    "This adjustment helps XGBoost:\n",
    "\n",
    "* Improve recall on the minority class\n",
    "* Perform better under PR-AUC, which emphasizes correct handling of the positive class\n",
    "* Avoid defaulting to predicting only the majority class\n",
    "\n",
    "This is conceptually similar to `class_weight='balanced'` used in scikit-learn models or in LightGBM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42ae27f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dummy (1/7)...\n",
      "  → Dummy PR-AUC: 0.0792\n",
      "Training LogReg (2/7)...\n",
      "  → LogReg PR-AUC: 0.2742\n",
      "Training DecisionTree (3/7)...\n",
      "  → DecisionTree PR-AUC: 0.2316\n",
      "Training RandomForest (4/7)...\n",
      "  → RandomForest PR-AUC: 0.4689\n",
      "Training XGBoost (5/7)...\n",
      "  → XGBoost PR-AUC: 0.3942\n",
      "Training LightGBM (6/7)...\n",
      "  → LightGBM PR-AUC: 0.3984\n",
      "Training CatBoost (7/7)...\n",
      "  → CatBoost PR-AUC: 0.4146\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>CV PR-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.468882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.414597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.398383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.394219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.274249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>0.231559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dummy</td>\n",
       "      <td>0.079208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Model  CV PR-AUC\n",
       "3  RandomForest   0.468882\n",
       "6      CatBoost   0.414597\n",
       "5      LightGBM   0.398383\n",
       "4       XGBoost   0.394219\n",
       "1        LogReg   0.274249\n",
       "2  DecisionTree   0.231559\n",
       "0         Dummy   0.079208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a proper stratified k-fold cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "results = []\n",
    "\n",
    "# Track progress\n",
    "total_models = len(models)\n",
    "completed = 0\n",
    "\n",
    "for name, (model, preproc) in models.items():\n",
    "    print(f\"Training {name} ({completed+1}/{total_models})...\")\n",
    "    \n",
    "    # Build pipeline\n",
    "    steps = []\n",
    "    if preproc != \"passthrough\":\n",
    "        steps.append((\"preprocess\", preproc))\n",
    "    steps.append((\"model\", model))\n",
    "    pipe = Pipeline(steps)\n",
    "    \n",
    "    try:\n",
    "        # Cross-validate with PR-AUC scoring\n",
    "        pr_auc_scores = cross_val_score(\n",
    "            pipe,\n",
    "            X_train, y_train,\n",
    "            cv=cv,\n",
    "            scoring='average_precision',  # Built-in scorer for PR-AUC\n",
    "            n_jobs=-1,\n",
    "            error_score='raise'\n",
    "        )\n",
    "        pr_auc_score = pr_auc_scores.mean()\n",
    "        print(f\"  → {name} PR-AUC: {pr_auc_score:.4f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  → Error with {name}: {str(e)}\")\n",
    "        pr_auc_score = float('nan')\n",
    "    \n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"CV PR-AUC\": pr_auc_score\n",
    "    })\n",
    "    \n",
    "    completed += 1\n",
    "\n",
    "# Sort results by performance\n",
    "benchmark_df = pd.DataFrame(results).sort_values(\"CV PR-AUC\", ascending=False)\n",
    "display(benchmark_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd55edc",
   "metadata": {},
   "source": [
    "## Example Model Metrics & Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36dcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    average_precision_score, roc_auc_score, precision_recall_curve,\n",
    "    confusion_matrix, classification_report, PrecisionRecallDisplay\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ac7407",
   "metadata": {},
   "source": [
    "| Metric                           | Why it matters                                                                                                                         |\n",
    "| -------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| **PR-AUC (Average Precision)**   | Focuses on the **minority class** (late deliveries). A random model would score ≈ 0.08. Anything higher reflects meaningful signal.    |\n",
    "| **ROC-AUC**                      | Measures general separability between late vs. on-time orders. It’s **threshold-independent**, useful to compare model capacity.       |\n",
    "| **Precision**                    | “Of the orders we flag as late, how many really are?” Important to avoid **alert fatigue** and **wasting Ops effort** on false alarms. |\n",
    "| **Recall**                       | “Of all true late orders, how many did we catch?” This defines **how much pain we actually prevent**.                                  |\n",
    "| **Confusion Matrix**             | Converts percentages into **absolute counts**, so we can estimate business impact.                                                     |\n",
    "| **Threshold for ≥80% Precision** | We tune the threshold so that 80% of flagged orders are actually late. Balances actionability with false alert risk.                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7cf64884",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 14\u001b[0m\n\u001b[0;32m      2\u001b[0m rf_pipe \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m      3\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreprocess\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocess_ohe),\n\u001b[0;32m      4\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, RandomForestClassifier(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     ))\n\u001b[0;32m     11\u001b[0m ])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# --- fit on full training set -------------------------------------\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m rf_pipe\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# ---  get probabilities and default predictions --------------------\u001b[39;00m\n\u001b[0;32m     17\u001b[0m y_prob \u001b[38;5;241m=\u001b[39m rf_pipe\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[0;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[0;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[0;32m    661\u001b[0m         )\n\u001b[1;32m--> 662\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator\u001b[38;5;241m.\u001b[39mfit(Xt, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlast_step_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[1;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    476\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    479\u001b[0m ]\n\u001b[0;32m    481\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m trees \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[0;32m    488\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[0;32m    489\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    490\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    491\u001b[0m )(\n\u001b[0;32m    492\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[0;32m    493\u001b[0m         t,\n\u001b[0;32m    494\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbootstrap,\n\u001b[0;32m    495\u001b[0m         X,\n\u001b[0;32m    496\u001b[0m         y,\n\u001b[0;32m    497\u001b[0m         sample_weight,\n\u001b[0;32m    498\u001b[0m         i,\n\u001b[0;32m    499\u001b[0m         \u001b[38;5;28mlen\u001b[39m(trees),\n\u001b[0;32m    500\u001b[0m         verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[0;32m    501\u001b[0m         class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight,\n\u001b[0;32m    502\u001b[0m         n_samples_bootstrap\u001b[38;5;241m=\u001b[39mn_samples_bootstrap,\n\u001b[0;32m    503\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    504\u001b[0m     )\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(trees)\n\u001b[0;32m    506\u001b[0m )\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     76\u001b[0m )\n\u001b[1;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- rebuild the pipeline exactly as in the benchmark -------------\n",
    "rf_pipe = Pipeline([\n",
    "    (\"preprocess\", preprocess_ohe),\n",
    "    (\"model\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=None,\n",
    "        class_weight=\"balanced\",\n",
    "        n_jobs=-1,\n",
    "        random_state=RANDOM_STATE\n",
    "    ))\n",
    "])\n",
    "\n",
    "# --- fit on full training set -------------------------------------\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "\n",
    "# ---  get probabilities and default predictions --------------------\n",
    "y_prob = rf_pipe.predict_proba(X_test)[:, 1]\n",
    "y_pred = (y_prob >= 0.50).astype(int)                 # default 0.5 cut-off\n",
    "\n",
    "# --- core metrics --------------------------------------------------\n",
    "pr_auc  = average_precision_score(y_test, y_prob)\n",
    "roc_auc = roc_auc_score(y_test, y_prob)\n",
    "print(f\"PR-AUC   : {pr_auc:.3f}\")\n",
    "print(f\"ROC-AUC  : {roc_auc:.3f}\\n\")\n",
    "print(\"Classification report (threshold 0.50):\")\n",
    "print(classification_report(y_test, y_pred, digits=3))\n",
    "\n",
    "# confusion matrix\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred),\n",
    "                  index=[\"Actual On-time\",\"Actual Late\"],\n",
    "                  columns=[\"Pred On-time\",\"Pred Late\"])\n",
    "print(\"\\nConfusion matrix:\")\n",
    "display(cm)\n",
    "\n",
    "# --- threshold to reach ≥80 % precision on \"Late\" ------------------\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "target_recall = 0.85\n",
    "# find the first threshold at which recall ≥ target_recall\n",
    "idx = np.where(recalls >= target_recall)[0]\n",
    "if idx.size:\n",
    "    best_thr = thresholds[idx[0]]\n",
    "    print(f\"Threshold for ≥{target_recall*100:.0f}% recall: {best_thr:.3f}\")\n",
    "    print(f\"  resulting precision     : {precisions[idx[0]]:.3f}\")\n",
    "else:\n",
    "    # fallback if model never reaches that recall\n",
    "    max_rec = recalls.max()\n",
    "    prec_at_max = precisions[recalls.argmax()]\n",
    "    print(f\"Model never reaches {target_recall*100:.0f}% recall; \"\n",
    "          f\"highest recall {max_rec:.3f} at precision {prec_at_max:.3f}\")\n",
    "\n",
    "# build predictions at your chosen threshold\n",
    "y_pred_recall = (y_prob >= best_thr).astype(int)\n",
    "\n",
    "print(\"\\nClassification report at recall-optimized threshold:\")\n",
    "print(classification_report(y_test, y_pred_recall, digits=3))\n",
    "\n",
    "# and a confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred_recall)\n",
    "display(pd.DataFrame(\n",
    "    cm,\n",
    "    index=[\"Actual On-time\",\"Actual Late\"],\n",
    "    columns=[\"Pred On-time\",\"Pred Late\"]\n",
    "))\n",
    "\n",
    "\n",
    "# quick PR-curve\n",
    "PrecisionRecallDisplay.from_predictions(y_test, y_prob)\n",
    "plt.title(\"RandomForest – Precision-Recall Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcb5dfc",
   "metadata": {},
   "source": [
    "| **Metric**                        | **Value**                                                                                                                                          | **Business Interpretation**                                                                                   |\n",
    "| --------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------- |\n",
    "| **PR-AUC**                        | **0.507**                                                                                                                                          | \\~6× better than random (baseline ≈ 0.08). Good for prioritizing which orders to inspect or intervene on.     |\n",
    "| **ROC-AUC**                       | 0.858                                                                                                                                              | Very strong overall separability. Confirms good feature signal.                                               |\n",
    "| **Precision (Thr = 0.50)**        | 94.7%                                                                                                                                              | Almost all flagged late orders **really were** late — very few false alarms.                                  |\n",
    "| **Recall (Thr = 0.50)**           | 18.3%                                                                                                                                              | We’re only catching \\~1 in 5 late orders at default threshold. May need to **lower threshold** to catch more. |\n",
    "| **Precision @ 80%**               | Threshold ≈ 0.38                                                                                                                                   | Keeps false positives tolerable while increasing recall to **\\~25%** — a good starting point for Ops rollout. |\n",
    "| **Confusion Matrix (Thr = 0.50)** | <ul><li>True Positives (TP): 319</li><li>False Positives (FP): 18</li><li>False Negatives (FN): 1423</li><li>True Negatives (TN): 20,227</li></ul> | Intervening on \\~337 orders (319 real + 18 false), leaving 1423 late orders still uncaught.                   |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363811d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.41742796907941\n"
     ]
    }
   ],
   "source": [
    "print(319/1423 * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
